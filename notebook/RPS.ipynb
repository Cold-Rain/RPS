{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11626,
     "status": "ok",
     "timestamp": 1727283548572,
     "user": {
      "displayName": "Vlad Reverend",
      "userId": "00733307170843819091"
     },
     "user_tz": -180
    },
    "id": "MXXTuy_o0sjk",
    "outputId": "7557f7ca-e1b4-4fe8-abc3-177e437afa17"
   },
   "outputs": [],
   "source": [
    "!pip install -q -U kaggle_environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11626,
     "status": "ok",
     "timestamp": 1727283548572,
     "user": {
      "displayName": "Vlad Reverend",
      "userId": "00733307170843819091"
     },
     "user_tz": -180
    },
    "id": "MXXTuy_o0sjk",
    "outputId": "7557f7ca-e1b4-4fe8-abc3-177e437afa17"
   },
   "outputs": [],
   "source": [
    "import itertools \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from kaggle_environments import make, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 11560,
     "status": "ok",
     "timestamp": 1727283562366,
     "user": {
      "displayName": "Vlad Reverend",
      "userId": "00733307170843819091"
     },
     "user_tz": -180
    },
    "id": "yz23vWHD0wcj",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting common.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile common.py\n",
    "\n",
    "'''\n",
    "общий модуль содержащий общие переменные функции и классы\n",
    "'''\n",
    "\n",
    "ROCK = 0\n",
    "'''\n",
    "Переменная хранящая значение для сущности камень. Значение равно 0\n",
    "'''\n",
    "\n",
    "PAPER = 1\n",
    "'''\n",
    "Переменная хранящая значение для сущности бумага. Значение равно 1\n",
    "'''\n",
    "\n",
    "SCISSORS = 2\n",
    "'''\n",
    "Переменная хранящая значение для сущности ножнецы. Значение равно 2\n",
    "'''\n",
    "\n",
    "RPS_VALUES = (ROCK, PAPER, SCISSORS)\n",
    "'''\n",
    "Все используемые значения в игре\n",
    "'''\n",
    "\n",
    "COUNTER_VALUES = {ROCK:PAPER, PAPER:SCISSORS, SCISSORS:ROCK}\n",
    "'''\n",
    "Словарь содержащий пары значение/противозначение, где \\\n",
    "противозначение всегда имеет преоритет в сравнении с значением.\n",
    "Например:\n",
    "камень/бумага, где бумага побеждает камень\n",
    "'''\n",
    "\n",
    "AGENTS = {\n",
    "    'paper':'paper_agent.py',\n",
    "    'rock':'rock_agent.py',\n",
    "    'scissors':'scissors_agent.py',\n",
    "    'copy_opponent':'copy_opponent_agent.py',\n",
    "    'reactionary':'reactionary_agent.py',\n",
    "    'counter_reactionar':'counter_reactionary_agent.py',\n",
    "    'statistical':'statistical_agent.py',\n",
    "    'randomizer':'randomizer_agent.py',\n",
    "    'loop':'loop_agent.py',\n",
    "    'LinearRegression':'lreg_agent.py',\n",
    "    'spline_interp':'spline_interp_agent.py',\n",
    "    'linear_interp':'linear_interp_agent.py',\n",
    "    'contr_opponent':'contr_opponent_agent.py',\n",
    "}\n",
    "'''\n",
    "словарь содержащий информацию о игровых агентах \n",
    "в виде название:файл\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import common as cmn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 268,
     "status": "ok",
     "timestamp": 1727283568145,
     "user": {
      "displayName": "Vlad Reverend",
      "userId": "00733307170843819091"
     },
     "user_tz": -180
    },
    "id": "bqTqV7B92rJ6",
    "outputId": "524f262c-1baf-44e3-8944-c3737b6bfeaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting contr_opponent_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile contr_opponent_agent.py\n",
    "\n",
    "import random\n",
    "import common as cmn\n",
    "\n",
    "class contr_opponent():\n",
    "     '''\n",
    "игровой агент стратегия которого заключается в том чтобы \\\n",
    "возвращать контрзначение для последнего значения выставленного опонентом\n",
    "\n",
    "    '''\n",
    "     \n",
    "     def __call__(self, observation, configuration):        \n",
    "        # в случае первой итерации, когда нет информации о последнем \n",
    "        # значении выставленном оппонентом, выбирается случайное значение \n",
    "        # из списка допустимых\n",
    "        if observation.step == 0:\n",
    "            return random.randrange(0, configuration.signs)\n",
    "        # в случае когда есть информация о последнем значении \n",
    "        # выставленном оппонентом\n",
    "        else:\n",
    "            return cmn.COUNTER_VALUES[observation.lastOpponentAction]\n",
    "\n",
    "            \n",
    "agent =  contr_opponent()\n",
    "\n",
    "# метод вызываемый из kaggle_environments\n",
    "def call_agent(obs, conf):\n",
    "    return agent(obs, conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting copy_opponent_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile copy_opponent_agent.py\n",
    "\n",
    "import random\n",
    "\n",
    "class copy_opponent():\n",
    "    '''\n",
    "игровой агент стратегия которого заключается в том чтобы копировать последнее\\\n",
    "значение, выставленное опонентом\n",
    "    '''\n",
    "\n",
    "    def __call__(self, observation, configuration):\n",
    "        # в случае первой итерации, когда нет информации о последнем \n",
    "        # значении выставленном оппонентом, выбирается случайное значение \n",
    "        # из списка допустимых\n",
    "        if observation.step == 0:\n",
    "            return random.randrange(0, configuration.signs)\n",
    "        # в случае когда есть информация о последнем значении \n",
    "        # выставленном оппонентом\n",
    "        else:\n",
    "            return observation.lastOpponentAction\n",
    "\n",
    "agent =  copy_opponent()\n",
    "\n",
    "# метод вызываемый из kaggle_environments\n",
    "def call_agent(obs, conf):\n",
    "    return agent(obs, conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting counter_reactionary_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile counter_reactionary_agent.py\n",
    "\n",
    "import random\n",
    "from  kaggle_environments.envs.rps.utils import get_score\n",
    "\n",
    "class counter_reactionary():\n",
    "    '''\n",
    "игровой агент стратегия которого заключается в том чтобы \\\n",
    "менять следующую значение агента значение, противоположное \\\n",
    "предыдущему значению оппонента\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.last_counter_action = None\n",
    "    \n",
    "    def __call__(self, observation, configuration):\n",
    "        if observation.step == 0:\n",
    "            # инициируем случайным образом значение для первого раунда\n",
    "            self.last_counter_action = random.randrange(0, configuration.signs)\n",
    "        else:\n",
    "            # оцениваем результат предыдущего раунда\n",
    "            score = get_score(self.last_counter_action, observation.lastOpponentAction)\n",
    "            if score == 1:\n",
    "                # меняем значение на предыдущий результат оппонента\n",
    "                self.last_counter_action = (self.last_counter_action + 2) % configuration.signs\n",
    "            else:\n",
    "                # меняем значение на противоположное по значимости предыдущему результату оппонента\n",
    "                self.last_counter_action = (observation.lastOpponentAction + 1) % configuration.signs\n",
    "        return self.last_counter_action\n",
    "\n",
    "\n",
    "agent = counter_reactionary()\n",
    "\n",
    "# метод вызываемый из kaggle_environments\n",
    "def call_agent(obs, conf):\n",
    "    return agent(obs, conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 265,
     "status": "ok",
     "timestamp": 1727283570954,
     "user": {
      "displayName": "Vlad Reverend",
      "userId": "00733307170843819091"
     },
     "user_tz": -180
    },
    "id": "7l6Ttw6qi0jk",
    "outputId": "d4889579-60ee-4991-8dfd-4747c24b07ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting linear_interp_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile linear_interp_agent.py\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "import common as cmn\n",
    "\n",
    "class linear_interp():\n",
    "    '''\n",
    "игровой агент стратегия которого заключается в том чтобы \\\n",
    "рассчитывать при помощи линейной интерполяции следующее значение оппонента \\\n",
    "и возвращать его противозначение\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.opponent_values = []\n",
    "\n",
    "    def __call__(self, observation, configuration):\n",
    "        if observation.step == 0:\n",
    "            # в случае начальной итерации\n",
    "            # инициализируем массив накопления данных\n",
    "            self.opponent_values = []\n",
    "            # возвращаем случайное значение\n",
    "            return random.randrange(0, configuration.signs)\n",
    "        else:\n",
    "            # сохраняем последнее значение оппонента в массив\n",
    "            self.opponent_values.append(observation.lastOpponentAction)\n",
    "            # генерируем порследовательность входных значений интерполяции\n",
    "            # по факту это порядковые номера выходных значений\n",
    "            x_data = list(range(1, len(self.opponent_values) + 1))\n",
    "            # определяем выходные значения (для наглядности)\n",
    "            y_data = self.opponent_values\n",
    "            # формируем приемлемые по типу аргументы для функции интерполяции\n",
    "            x = np.array(x_data)\n",
    "            y = np.array(y_data)\n",
    "            # создаем интерполятор\n",
    "            interp = interp1d(x, y, kind='linear', fill_value='extrapolate')\n",
    "            # формируем значение аргумента, для которого нужно получить \n",
    "            # прогнозируемое значение\n",
    "            next_x = max(x_data) + 1\n",
    "            # формируем приемлемые по типу аргументы для функции интерполяции\n",
    "            new_x = np.array([next_x])\n",
    "            # вычисляем прогнозируемое значение стратегии оппонента\n",
    "            y_pred = interp(new_x)\n",
    "            predicted_val = y_pred[0] \n",
    "            # преобразуем полученное значение в область допустимых значений\n",
    "            corrected_val = min(cmn.RPS_VALUES , key=lambda x: abs(x - predicted_val))\n",
    "            # получаем и возвращаем контр-значение для спрогнозированного значения\n",
    "            counter_val = cmn.COUNTER_VALUES[corrected_val]\n",
    "            return counter_val\n",
    "\n",
    "agent = linear_interp()\n",
    "\n",
    "# метод вызываемый из kaggle_environments\n",
    "def call_agent(obs, conf):\n",
    "    return agent(obs, conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 249,
     "status": "ok",
     "timestamp": 1727256681093,
     "user": {
      "displayName": "Vlad Reverend",
      "userId": "00733307170843819091"
     },
     "user_tz": -180
    },
    "id": "wv6Ip6M004xa",
    "outputId": "932dfbc5-c1f6-4018-c02b-19a354e1e623"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting loop_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile loop_agent.py\n",
    "\n",
    "import common as cmn\n",
    "\n",
    "class loop():\n",
    "    '''\n",
    "игровой агент стратегия которого заключается в том \\\n",
    "чтобы возвращать RPS значения по кругу\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.loop_idx = None\n",
    "\n",
    "    def __call__(self, observation, configuration):\n",
    "        if observation.step == 0:\n",
    "            # первоначальная инициализация \n",
    "            # для первой итерации сравнения агентов\n",
    "            self.loop_idx = 0\n",
    "        else:\n",
    "            # изменяем индекс массива\n",
    "            self.loop_idx += 1\n",
    "            if self.loop_idx >= len(cmn.RPS_VALUES):\n",
    "                self.loop_idx = 0\n",
    "        # возвращаем значение для текущей итерации\n",
    "        return cmn.RPS_VALUES[self.loop_idx]\n",
    "\n",
    "agent = loop()\n",
    "\n",
    "# метод вызываемый из kaggle_environments\n",
    "def call_agent(obs, conf):\n",
    "    return agent(obs, conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 542,
     "status": "ok",
     "timestamp": 1727283594525,
     "user": {
      "displayName": "Vlad Reverend",
      "userId": "00733307170843819091"
     },
     "user_tz": -180
    },
    "id": "FC6_QWe9k3rr",
    "outputId": "6d7159ef-7c9b-4b25-de44-eb1dbd1e8075"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lreg_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lreg_agent.py\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import common as cmn\n",
    "\n",
    "class linear_regression():\n",
    "    '''\n",
    "игровой агент стратегия которого заключается в том чтобы \\\n",
    "рассчитывать по линейной регрессии следующее значение оппонента \\\n",
    "и возвращать его противозначение\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.opponent_values = []\n",
    "\n",
    "    def __call__(self, observation, configuration):\n",
    "        if observation.step == 0:\n",
    "            # в случае начальной итерации\n",
    "            # инициализируем массив накопления данных\n",
    "            self.opponent_values = []\n",
    "            # возвращаем случайное значение\n",
    "            return random.randrange(0, configuration.signs)\n",
    "        else:\n",
    "            # сохраняем последнее значение оппонента в массив\n",
    "            self.opponent_values.append(observation.lastOpponentAction)\n",
    "            # генерируем порследовательность входных значений интерполяции\n",
    "            # по факту это порядковые номера выходных значений\n",
    "            x_data = list(range(1, len(self.opponent_values) + 1))\n",
    "            # определяем выходные значения (для наглядности)\n",
    "            y_data = self.opponent_values\n",
    "            # формируем приемлемые по типу аргументы для функции интерполяции\n",
    "            x = np.array(x_data).reshape((-1, 1))\n",
    "            y = np.array(y_data)\n",
    "            # создаем модель регрессии и вычисляем оптимальные значение весов\n",
    "            model = LinearRegression().fit(x, y)\n",
    "            # вычисляем прогнозируемое значение стратегии оппонента\n",
    "            y_pred = model.predict(x)\n",
    "            predicted_val = y_pred[0] \n",
    "            # преобразуем полученное значение в область допустимых значений\n",
    "            corrected_val = \\\n",
    "                min(cmn.RPS_VALUES , key=lambda x: abs(x - predicted_val))\n",
    "            # получаем и возвращаем контр-значение \n",
    "            # для спрогнозированного значения\n",
    "            counter_val = cmn.COUNTER_VALUES[corrected_val]\n",
    "            return counter_val\n",
    "\n",
    "agent = linear_regression()\n",
    "\n",
    "# метод вызываемый из kaggle_environments\n",
    "def call_agent(obs, conf):\n",
    "    return agent(obs, conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting paper_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile paper_agent.py\n",
    "\n",
    "import common as cmn\n",
    "\n",
    "class paper():\n",
    "    '''\n",
    "игровой агент стратегия которого заключается в том \\\n",
    "чтобы всегда возвращать бумагу\n",
    "   '''\n",
    "    \n",
    "    def __call__(self, observation, configuration):\n",
    "       # всегда возвращаем бумагу\n",
    "       return cmn.PAPER\n",
    "\n",
    "agent = paper()\n",
    "\n",
    "# метод вызываемый из kaggle_environments\n",
    "def call_agent(obs, conf):\n",
    "    return agent(obs, conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting randomizer_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile randomizer_agent.py\n",
    "\n",
    "import random\n",
    "\n",
    "class randomizer():\n",
    "    '''\n",
    "игровой агент стратегия которого заключается в том \\\n",
    "чтобы всегда возвращать случайное значение\n",
    "    '''\n",
    "\n",
    "    def __call__(self, observation, configuration):\n",
    "        # возвращаем случайное значение\n",
    "        return random.randrange(0, configuration.signs)\n",
    "\n",
    "agent = randomizer()\n",
    "\n",
    "# метод вызываемый из kaggle_environments\n",
    "def call_agent(obs, conf):\n",
    "    return agent(obs, conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reactionary_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reactionary_agent.py\n",
    "\n",
    "import random\n",
    "from  kaggle_environments.envs.rps.utils import get_score\n",
    "\n",
    "class reactionary():\n",
    "    '''\n",
    "игровой агент стратегия которого заключается в том чтобы \\\n",
    "в случае проигрыша или ничьей менять значение на противоположное \\\n",
    "по значимости предыдущему результату оппонента\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.last_react_action = None\n",
    "\n",
    "    def __call__(self, observation, configuration):\n",
    "        if observation.step == 0:\n",
    "            # инициируем случайным образом значение для первого раунда\n",
    "            self.last_react_action = random.randrange(0, configuration.signs)\n",
    "        else:\n",
    "            # оцениваем результат предыдущего раунда\n",
    "            score = get_score(self.last_react_action, observation.lastOpponentAction)\n",
    "            # в случае проигрыша или ничьей \n",
    "            if score <= 1:\n",
    "                # меняем значение на противоположное по значимости \n",
    "                # предыдущему результату оппонента\n",
    "                self.last_react_action = \\\n",
    "                    (observation.lastOpponentAction + 1) % configuration.signs\n",
    "        return self.last_react_action\n",
    "\n",
    "agent = reactionary()\n",
    "\n",
    "# метод вызываемый из kaggle_environments\n",
    "def call_agent(obs, conf):\n",
    "    return agent(obs, conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting rock_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile rock_agent.py\n",
    "\n",
    "import common as cmn\n",
    "\n",
    "class rock():\n",
    "    '''\n",
    "игровой агент стратегия которого заключается в том \\\n",
    "чтобы всегда возвращать камень\n",
    "    '''\n",
    "\n",
    "    def __call__(self, observation, configuration):\n",
    "        # всегда возвращаем камень\n",
    "        return cmn.ROCK\n",
    "\n",
    "agent = rock()\n",
    "\n",
    "# метод вызываемый из kaggle_environments\n",
    "def call_agent(obs, conf):\n",
    "    return agent(obs, conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scissors_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scissors_agent.py\n",
    "\n",
    "import common as cmn\n",
    "\n",
    "class scissors():\n",
    "    '''\n",
    "игровой агент стратегия которого заключается в том \\\n",
    "чтобы всегда возвращать ножницы\n",
    "    '''\n",
    "\n",
    "    def __call__(self, observation, configuration):\n",
    "      # всегда возвращаем ножницы\n",
    "      return cmn.SCISSORS\n",
    "\n",
    "agent = scissors()\n",
    "\n",
    "# метод вызываемый из kaggle_environments\n",
    "def call_agent(obs, conf):\n",
    "    return agent(obs, conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting spline_interp_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile spline_interp_agent.py\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "import common as cmn\n",
    "\n",
    "class spline_interp():\n",
    "    '''\n",
    "игровой агент стратегия которого заключается в том чтобы \\\n",
    "рассчитывать при помощи сплайн-интерполяции следующее значение оппонента \\\n",
    "и возвращать его противозначение\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.opponent_values = []\n",
    "\n",
    "    def __call__(self, observation, configuration):\n",
    "        if observation.step < 4:\n",
    "            if observation.step == 0:\n",
    "                # в случае начальной итерации\n",
    "                # инициализируем массив накопления данных\n",
    "                self.opponent_values = []\n",
    "            else:\n",
    "                # продолжаем накапливать данные \n",
    "                # до достижения минимально необходжимого количества\n",
    "                self.opponent_values.append(observation.lastOpponentAction)\n",
    "            # возвращаем случайное значение\n",
    "            return random.randrange(0, configuration.signs)\n",
    "        else:\n",
    "            # сохраняем последнее значение оппонента в массив\n",
    "            self.opponent_values.append(observation.lastOpponentAction)\n",
    "            # генерируем порследовательность входных значений интерполяции\n",
    "            # по факту это порядковые номера выходных значений\n",
    "            x_data = list(range(1, len(self.opponent_values) + 1))\n",
    "            # определяем выходные значения (для наглядности)\n",
    "            y_data = self.opponent_values\n",
    "            # формируем приемлемые по типу аргументы для функции интерполяции\n",
    "            x = np.array(x_data)\n",
    "            y = np.array(y_data)\n",
    "            # создаем интерполятор\n",
    "            interp = interp1d(x, y, kind='cubic', fill_value='extrapolate') \n",
    "            # формируем значение аргумента, для которого нужно получить \n",
    "            # прогнозируемое значение\n",
    "            next_x = max(x_data) + 1\n",
    "            # формируем приемлемые по типу аргументы для функции интерполяции\n",
    "            new_x = np.array([next_x])\n",
    "            # вычисляем прогнозируемое значение стратегии оппонента\n",
    "            y_pred = interp(new_x)\n",
    "            predicted_val = y_pred[0] \n",
    "            # преобразуем полученное значение в область допустимых значений\n",
    "            corrected_val = min(cmn.RPS_VALUES , key=lambda x: abs(x - predicted_val))\n",
    "            # получаем и возвращаем контр-значение для спрогнозированного значения\n",
    "            counter_val = cmn.COUNTER_VALUES[corrected_val]\n",
    "            return counter_val\n",
    "\n",
    "agent = spline_interp()\n",
    "\n",
    "# метод вызываемый из kaggle_environments\n",
    "def call_agent(obs, conf):\n",
    "    return agent(obs, conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting statistical_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile statistical_agent.py\n",
    "\n",
    "import random\n",
    "\n",
    "class statistical():\n",
    "    '''\n",
    "игровой агент стратегия которого заключается в том чтобы \\\n",
    "найти среди статистики наиболее часто встречающееся значение опонента, \\\n",
    "и вернуть противоположное по значимости значение\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.action_histogram = {}\n",
    "\n",
    "    def __call__(self, observation, configuration):\n",
    "        if observation.step == 0:\n",
    "            # в случае начального раунда возвращаем \n",
    "            # инициализируем словарь исторических данных\n",
    "            self.action_histogram = {}\n",
    "            # возвращаем случаное значение\n",
    "            return random.randrange(0, configuration.signs)\n",
    "        # берем последнее значение оппонента и инкрементируем его счетчик\n",
    "        action = observation.lastOpponentAction\n",
    "        if action not in self.action_histogram:\n",
    "            self.action_histogram[action] = 0\n",
    "        self.action_histogram[action] += 1\n",
    "        # находим наиболее часто встречающеемя значение\n",
    "        mode_action = None\n",
    "        mode_action_count = None\n",
    "        for k, v in self.action_histogram.items():\n",
    "            if mode_action_count is None or v > mode_action_count:\n",
    "                mode_action = k\n",
    "                mode_action_count = v\n",
    "                continue\n",
    "        # возвращаем его противозначение\n",
    "        return  (mode_action + 1) % configuration.signs\n",
    "\n",
    "agent = statistical()\n",
    "\n",
    "# метод вызываемый из kaggle_environments\n",
    "def call_agent(obs, conf):\n",
    "    return agent(obs, conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'counter_reactionar': 7,\n",
      "'spline_interp': 7,\n",
      "'reactionary': 6,\n",
      "'linear_interp': 6,\n",
      "'statistical': 5,\n",
      "'contr_opponent': 5,\n",
      "'copy_opponent': 3,\n",
      "'LinearRegression': 3,\n",
      "'paper': 1,\n",
      "'rock': 1,\n",
      "'scissors': 1,\n",
      "'loop': 1,\n",
      "'randomizer': 0 \n",
      "\n",
      "Total agents count: 13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# создаем уникальные комбинации агентов для тестирования\n",
    "agent_comb = list(itertools.combinations(cmn.AGENTS.keys(), 2))\n",
    "# определяем словарь результатов\n",
    "results ={}\n",
    "# запускаем тестирование агентов\n",
    "for a1,  a2 in agent_comb:\n",
    "    # получаем названия файлов тестируемых агентов\n",
    "    af1 = cmn.AGENTS[a1]\n",
    "    af2 = cmn.AGENTS[a2]\n",
    "    # выполняем тестирование и сохраняем результаты\n",
    "    results[(a1, a2)] = evaluate(\n",
    "        \"rps\", \n",
    "        [af1, af2], \n",
    "        configuration={\"episodeSteps\": 100} )[0]\n",
    "#print(\"\\n\"*3, \"{\\n\" + \"\\n\".join(\"   {!r}: {!r},\".format(k, v) for k, v in results.items()).strip(',') + \"\\n}\", \"\\n\"*3)\n",
    "# определяем победителей\n",
    "winners = [k[0] if v[0] > v[1] else k[1] if v[0] < v[1] else None for k, v in results.items()]\n",
    "# формируем и сортируем статистику\n",
    "stats  = { t[0]:t[1] for t in sorted([(k, winners.count(k)) for k in cmn.AGENTS.keys()], key=lambda t: t[1], reverse=True)}\n",
    "# выводим результаты\n",
    "print(\"\\n\" + \"\\n\".join(\"{!r}: {!r},\".format(k, v) for k, v in stats.items()).strip(','), \"\\n\")\n",
    "print(f\"Total agents count: {len(cmn.AGENTS)}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1XP0dsb-T3ORPYv4YQFV5j23PknFH06O6",
     "timestamp": 1727256204249
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
